{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import random\n",
    "import argparse\n",
    "# from network.resnet import resnet18, resnet34\n",
    "# from network.pointnet import PointNetCls\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from Models import FMNIST_classifier\n",
    "from fmnist_prepare_subset_select_train_val_test import F_MNIST\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "from termcolor import cprint\n",
    "# from knn_utils import calc_knn_graph, calc_topo_weights_with_components_idx\n",
    "from subset_select_ipot_non_uniform_git import subset_select_ipot as ss_ipot\n",
    "from noise import noisify_with_P, noisify_cifar10_asymmetric, noisify_cifar100_asymmetric, noisify_pairflip, noisify_modelnet40_asymmetric\n",
    "import copy\n",
    "from scipy.stats import mode\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = \"cpu\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual noise 0.80\n"
     ]
    }
   ],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(77 + worker_id)\n",
    "\n",
    "models_path = \"G:\\\\My Drive\\\\Research Codes\\\\Subset Selection Paper\\\\Neural Network Classifier\\\\models\\\\UCI-subset-select\\\\Fashion-MNIST\\\\\"\n",
    "\n",
    "train_val_ratio = 0.8\n",
    "trust_prop = 0.5\n",
    "noise_level = 0.8\n",
    "batch_size_train = 512\n",
    "num_classes = 10\n",
    "random_seed = 42\n",
    "max_epochs = 200\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "\n",
    "trainset = F_MNIST(root='./data', split='train', train_ratio=train_val_ratio,trust_prop=trust_prop,  download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=0, worker_init_fn=_init_fn)\n",
    "\n",
    "noise_y_train_labels0, noise_y_train_indices = trainset.get_noisy_labels_with_indices()\n",
    "noise_y_train, p, _ = noisify_with_P(noise_y_train_labels0, nb_classes=num_classes, noise=noise_level, random_state=random_seed)\n",
    "trainset.update_corrupted_label(noise_y_train, noise_y_train_indices)\n",
    "\n",
    "valset = F_MNIST(root='./data', split='val', train_ratio=train_val_ratio, trust_prop=trust_prop, download=True, transform=transform)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=512, shuffle=False, num_workers=0)\n",
    "\n",
    "testset = F_MNIST(root='./data', split='test', download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=512, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "unique_labels = [int(i) for i in list(np.linspace(0, 10, 10, endpoint=False))]\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net = FMNIST_classifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(max_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = []\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # _, images, labels, _, _ = data\n",
    "        images, labels, _, _, _ = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, _ = net(images.double().to(device))\n",
    "        loss = criterion(outputs, labels.long().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss.append(loss.item())\n",
    "        # avg_loss.append(torch.tensor(running_loss).mean())\n",
    "    print(\"epoch={0:d},  avg_loss = {1:0.4f}\".format(\n",
    "        epoch, torch.tensor(running_loss).mean()))\n",
    "\n",
    "    if True:\n",
    "        classes = tuple([str(i) for i in unique_labels])\n",
    "        correct_pred = {classname: 0 for classname in classes}\n",
    "        total_pred = {classname: 0 for classname in classes}\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                images, labels, _, _, _ = data\n",
    "                outputs, _ = net(images.double().to(device))\n",
    "                _, predictions = torch.max(outputs, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions.cpu() == labels).sum().item()\n",
    "            print(f'val set accuraccy: {100 * correct / total} %')\n",
    "            val_acc.append(100 * correct / total)\n",
    "\n",
    "        if val_acc[-1] > best_accuracy:\n",
    "            best_accuracy = val_acc[-1]\n",
    "            net_path = models_path + \"FMNIST_clean\"+\".pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val-accuracy': val_acc,\n",
    "                'train-accuracy': train_acc}, net_path)\n",
    "\n",
    "        classes = tuple([str(i) for i in unique_labels])\n",
    "        correct_pred = {classname: 0 for classname in classes}\n",
    "        total_pred = {classname: 0 for classname in classes}\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in trainloader:\n",
    "                images, labels, _, _, _ = data\n",
    "                outputs, _ = net(images.double().to(device))\n",
    "                _, predictions = torch.max(outputs, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions.cpu() == labels).sum().item()\n",
    "        print(f'train set accuracy: {100 * correct / total} %')\n",
    "        train_acc.append(100 * correct / total)\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "# saving training accuracy list along with model with best accuracy\n",
    "net_path = models_path + \"FMNIST_clean\"+\".pth\"\n",
    "best_net_dict = torch.load(net_path)\n",
    "best_net_dict['val-accuracy'] = val_acc\n",
    "best_net_dict['train-accuracy'] = train_acc\n",
    "torch.save(best_net_dict, net_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "net_path = models_path + \"FMNIST_clean\"+\".pth\"\n",
    "best_net_dict = torch.load(net_path)\n",
    "\n",
    "iters = list(range(0, 100))\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(iters, best_net_dict['val-accuracy'],\n",
    "         \"-.\", color=\"r\", label=\"validation\")\n",
    "axs.plot(iters, best_net_dict['train-accuracy'],\n",
    "         \"-.\", color=\"b\", label=\"train\")\n",
    "axs.set_xlabel(\"iters.\")\n",
    "axs.set_ylabel(\"accuracy\")\n",
    "fig.legend(ncol=3, loc=(0.4, 0.13))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(77 + worker_id)\n",
    "\n",
    "\n",
    "models_path = \"G:\\\\My Drive\\\\Research Codes\\\\Subset Selection Paper\\\\Neural Network Classifier\\\\models\\\\UCI-subset-select\\\\Fashion-MNIST\\\\\"\n",
    "\n",
    "train_val_ratio = 0.8\n",
    "trust_prop = 0.5\n",
    "\n",
    "batch_size_train = 512\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "noise_level = 0.8\n",
    "random_seed = 42\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "trainset = F_MNIST(root='./data', split='train', train_ratio=train_val_ratio,\n",
    "                 trust_prop=trust_prop,  download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=512, shuffle=True, num_workers=0, worker_init_fn=_init_fn)\n",
    "\n",
    "\n",
    "noise_y_train_labels0, noise_y_train_indices = trainset.get_noisy_labels_with_indices()\n",
    "noise_y_train, p, _ = noisify_with_P(\n",
    "    noise_y_train_labels0, nb_classes=num_classes, noise=noise_level, random_state=random_seed)\n",
    "trainset.update_corrupted_label(noise_y_train, noise_y_train_indices)\n",
    "\n",
    "valset = F_MNIST(root='./data', split='val', train_ratio=train_val_ratio,\n",
    "               trust_prop=trust_prop, download=True, transform=transform_train)\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset, batch_size=512, shuffle=False, num_workers=0)\n",
    "\n",
    "testset = F_MNIST(root='./data', split='test',\n",
    "                download=True, transform=transform_train)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=512, shuffle=False, num_workers=0)\n",
    "\n",
    "max_epochs = 100\n",
    "unique_labels = [int(i) for i in list(np.linspace(0, 10, 10, endpoint=False))]\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net = FMNIST_classifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(\n",
    "    0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(max_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = []\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # _, images, labels, _, _ = data\n",
    "        images, labels, _, _, _ = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, _ = net(images.double().to(device))\n",
    "        loss = criterion(outputs, labels.long().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss.append(loss.item())\n",
    "        # avg_loss.append(torch.tensor(running_loss).mean())\n",
    "    print(\"epoch={0:d},  avg_loss = {1:0.4f}\".format(\n",
    "        epoch, torch.tensor(running_loss).mean()))\n",
    "\n",
    "    if True:\n",
    "        classes = tuple([str(i) for i in unique_labels])\n",
    "        correct_pred = {classname: 0 for classname in classes}\n",
    "        total_pred = {classname: 0 for classname in classes}\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                images, labels, _, _, _ = data\n",
    "                outputs, _ = net(images.double().to(device))\n",
    "                _, predictions = torch.max(outputs, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions.cpu() == labels).sum().item()\n",
    "            print(f'val set accuraccy: {100 * correct / total} %')\n",
    "            val_acc.append(100 * correct / total)\n",
    "\n",
    "        if val_acc[-1] > best_accuracy:\n",
    "            best_accuracy = val_acc[-1]\n",
    "            net_path = models_path + \"FMNIST_noisy\"+\".pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val-accuracy': val_acc,\n",
    "                'train-accuracy': train_acc}, net_path)\n",
    "\n",
    "        classes = tuple([str(i) for i in unique_labels])\n",
    "        correct_pred = {classname: 0 for classname in classes}\n",
    "        total_pred = {classname: 0 for classname in classes}\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in trainloader:\n",
    "                images, labels, _, _, _ = data\n",
    "                outputs, _ = net(images.double().to(device))\n",
    "                _, predictions = torch.max(outputs, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predictions.cpu() == labels).sum().item()\n",
    "        print(f'train set accuracy: {100 * correct / total} %')\n",
    "        train_acc.append(100 * correct / total)\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "# saving training accuracy list along with model with best accuracy\n",
    "net_path = models_path + \"FMNIST_noisy\"+\".pth\"\n",
    "best_net_dict = torch.load(net_path)\n",
    "best_net_dict['val-accuracy'] = val_acc\n",
    "best_net_dict['train-accuracy'] = train_acc\n",
    "torch.save(best_net_dict, net_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "net_path = models_path + \"FMNIST_noisy\"+\".pth\"\n",
    "best_net_dict = torch.load(net_path)\n",
    "\n",
    "\n",
    "iters = list(range(0, 100))\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(iters, best_net_dict['val-accuracy'], \"-.\", color=\"r\", label=\"validation\")\n",
    "axs.plot(iters, best_net_dict['train-accuracy'], \"-.\", color=\"b\", label=\"train\")\n",
    "axs.set_xlabel(\"iters.\")\n",
    "axs.set_ylabel(\"accuracy\")\n",
    "fig.legend(ncol=3, loc=(0.4, 0.13))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(77 + worker_id)\n",
    "\n",
    "\n",
    "models_path = \"G:\\\\My Drive\\\\Research Codes\\\\Subset Selection Paper\\\\Neural Network Classifier\\\\models\\\\UCI-subset-select\\\\Fashion-MNIST\\\\\"\n",
    "\n",
    "train_val_ratio = 0.8\n",
    "trust_prop = 0.5\n",
    "\n",
    "batch_size_train = 512\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "noise_level = 0.8\n",
    "random_seed = 42\n",
    "\n",
    "cs = [1, 2, 3, 4, 5, 6, 7, 8, 20]\n",
    "max_epochs = 200\n",
    "gamma_ss = 0.01\n",
    "\n",
    "# models_path + \"ss_1 \" +  \"cifar10 \" + \"c={cs:2d}\".format(cs=c)+\".pth\"\n",
    "\n",
    "for c in cs:\n",
    "    print(\"c = \", c)\n",
    "\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    transform_train = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    trainset = F_MNIST(root='./data', split='train', train_ratio=train_val_ratio,\n",
    "                     trust_prop=trust_prop,  download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=512, shuffle=True, num_workers=0, worker_init_fn=_init_fn)\n",
    "\n",
    "    noise_y_train_labels0, noise_y_train_indices = trainset.get_noisy_labels_with_indices()\n",
    "    noise_y_train, p, _ = noisify_with_P(\n",
    "        noise_y_train_labels0, nb_classes=num_classes, noise=noise_level, random_state=random_seed)\n",
    "    trainset.update_corrupted_label(noise_y_train, noise_y_train_indices)\n",
    "\n",
    "    valset = F_MNIST(root='./data', split='val', train_ratio=train_val_ratio,\n",
    "                   trust_prop=trust_prop, download=True, transform=transform_train)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        valset, batch_size=512, shuffle=False, num_workers=0)\n",
    "\n",
    "    testset = F_MNIST(root='./data', split='test',\n",
    "                    download=True, transform=transform_train)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=512, shuffle=False, num_workers=0)\n",
    "\n",
    "    unique_labels = [int(i)\n",
    "                     for i in list(np.linspace(0, 10, 10, endpoint=False))]\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    net = FMNIST_classifier().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(\n",
    "        0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    best_accuracy = 0\n",
    "\n",
    "    for epoch in range(max_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = []\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            # _, images, labels, _, _ = data\n",
    "            images, labels, weights, cd_y, idx = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, encodings = net(images.double().to(device))\n",
    "\n",
    "            x = encodings[cd_y == 1].detach().cpu()\n",
    "            y = encodings[cd_y == 0].detach().cpu()\n",
    "            x_labels = labels[cd_y == 1].detach().cpu()\n",
    "            y_labels = labels[cd_y == 0].detach().cpu()\n",
    "            x_idx = idx[cd_y == 1].detach().cpu()\n",
    "            y_idx = idx[cd_y == 0].detach().cpu()\n",
    "\n",
    "            x_labels_onehot = (F.one_hot(x_labels.long(), num_classes=num_classes)).to(\n",
    "                device).double()\n",
    "\n",
    "            mu = 1/x.shape[0]*np.ones(x.shape[0])\n",
    "            nu = 1/y.shape[0]*np.ones(y.shape[0])\n",
    "            costs, P, _, _ = ss_ipot(x, y, mu, nu, c,  gamma_ss, max_outer_iter=20,\n",
    "                                     max_inner_iter=20, wd=2, disp_iter=False, return_map=True)\n",
    "\n",
    "            P_torch = torch.from_numpy(P).to(device)\n",
    "            y_labels_hat = (P_torch.T@x_labels_onehot.double()).to(device)\n",
    "\n",
    "            input_labels_hat = torch.zeros_like(\n",
    "                outputs, device=device, dtype=torch.double)\n",
    "            input_labels_hat[cd_y == 1] = 1 / \\\n",
    "                x.shape[0] * (x_labels_onehot.double())\n",
    "            input_labels_hat[cd_y == 0] = y_labels_hat\n",
    "\n",
    "            loss = - torch.sum(input_labels_hat*F.log_softmax(outputs, dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss.item())\n",
    "            # avg_loss.append(torch.tensor(running_loss).mean())\n",
    "        print(\"epoch={0:d},  avg_loss = {1:0.4f}\".format(\n",
    "            epoch, torch.tensor(running_loss).mean()))\n",
    "\n",
    "        if True:\n",
    "            classes = tuple([str(i) for i in unique_labels])\n",
    "            correct_pred = {classname: 0 for classname in classes}\n",
    "            total_pred = {classname: 0 for classname in classes}\n",
    "            total = 0\n",
    "            correct = 0\n",
    "\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in valloader:\n",
    "                    images, labels, _, _, _ = data\n",
    "                    outputs, _ = net(images.double().to(device))\n",
    "                    _, predictions = torch.max(outputs, dim=1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predictions.cpu() == labels).sum().item()\n",
    "                print(f'val set accuraccy: {100 * correct / total} %')\n",
    "                val_acc.append(100 * correct / total)\n",
    "\n",
    "            if val_acc[-1] > best_accuracy:\n",
    "                best_accuracy = val_acc[-1]\n",
    "                net_path = models_path + \"ss_1 \" + \\\n",
    "                    \"fmnist \" + \"c={cs:2d}\".format(cs=c)+\".pth\"\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val-accuracy': val_acc,\n",
    "                    'train-accuracy': train_acc}, net_path)\n",
    "\n",
    "            classes = tuple([str(i) for i in unique_labels])\n",
    "            correct_pred = {classname: 0 for classname in classes}\n",
    "            total_pred = {classname: 0 for classname in classes}\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in trainloader:\n",
    "                    images, labels, _, _, _ = data\n",
    "                    outputs, _ = net(images.double().to(device))\n",
    "                    _, predictions = torch.max(outputs, dim=1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predictions.cpu() == labels).sum().item()\n",
    "            print(f'train set accuracy: {100 * correct / total} %')\n",
    "            train_acc.append(100 * correct / total)\n",
    "\n",
    "    print('Finished Training')\n",
    "    # saving training accuracy list along with model with best accuracy\n",
    "    net_path = models_path + \"ss_1 \" + \\\n",
    "        \"fmnist \" + \"c={cs:2d}\".format(cs=c)+\".pth\"\n",
    "    best_net_dict = torch.load(net_path)\n",
    "    best_net_dict['val-accuracy'] = val_acc\n",
    "    best_net_dict['train-accuracy'] = train_acc\n",
    "    torch.save(best_net_dict, net_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94a50e03b059fb6038791710436d907f8274645c3a91865674da183d5c69a6a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
